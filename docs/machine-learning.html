<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Identifying data and statistical projects using machine learning | Methodology for measuring and estimating funding to data and statistics</title>
  <meta name="description" content="Technical note for the Partner Report on Support to Statistics" />
  <meta name="generator" content="bookdown 0.28 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Identifying data and statistical projects using machine learning | Methodology for measuring and estimating funding to data and statistics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Technical note for the Partner Report on Support to Statistics" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Identifying data and statistical projects using machine learning | Methodology for measuring and estimating funding to data and statistics" />
  
  <meta name="twitter:description" content="Technical note for the Partner Report on Support to Statistics" />
  

<meta name="author" content="Yu Tian" />
<meta name="author" content="Archita Misra" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="monitoring-funding-to-statistics-with-accuracy.html"/>
<link rel="next" href="monitoring-funding-to-statistics-with-reduced-reporting-lag.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="toc-logo"><a href="./"><img src="P21_logo.png"></a></li>
<li><a href="./">PRESS Methodology note</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="1" data-path="background.html"><a href="background.html"><i class="fa fa-check"></i><b>1</b> Background</a></li>
<li class="chapter" data-level="2" data-path="monitoring-funding-to-statistics-with-accuracy.html"><a href="monitoring-funding-to-statistics-with-accuracy.html"><i class="fa fa-check"></i><b>2</b> Monitoring funding to statistics with accuracy</a>
<ul>
<li class="chapter" data-level="2.1" data-path="monitoring-funding-to-statistics-with-accuracy.html"><a href="monitoring-funding-to-statistics-with-accuracy.html#oecds-creditor-reporting-system-crs"><i class="fa fa-check"></i><b>2.1</b> OECD’s Creditor Reporting System (CRS)</a></li>
<li class="chapter" data-level="2.2" data-path="monitoring-funding-to-statistics-with-accuracy.html"><a href="monitoring-funding-to-statistics-with-accuracy.html#P21-online-survey"><i class="fa fa-check"></i><b>2.2</b> PARIS21’s annual online survey</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="machine-learning.html"><a href="machine-learning.html"><i class="fa fa-check"></i><b>3</b> Identifying data and statistical projects using machine learning</a>
<ul>
<li class="chapter" data-level="3.1" data-path="machine-learning.html"><a href="machine-learning.html#reading-the-crs-data"><i class="fa fa-check"></i><b>3.1</b> Reading the CRS data</a></li>
<li class="chapter" data-level="3.2" data-path="machine-learning.html"><a href="machine-learning.html#preparing-the-data"><i class="fa fa-check"></i><b>3.2</b> Preparing the data</a></li>
<li class="chapter" data-level="3.3" data-path="machine-learning.html"><a href="machine-learning.html#a-title-pattern-matching"><i class="fa fa-check"></i><b>3.3</b> <strong>A</strong>: Title pattern matching</a></li>
<li class="chapter" data-level="3.4" data-path="machine-learning.html"><a href="machine-learning.html#b-text-mining-of-long-descriptions"><i class="fa fa-check"></i><b>3.4</b> <strong>B</strong>: Text mining of long descriptions</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="monitoring-funding-to-statistics-with-reduced-reporting-lag.html"><a href="monitoring-funding-to-statistics-with-reduced-reporting-lag.html"><i class="fa fa-check"></i><b>4</b> Monitoring funding to statistics with reduced reporting lag</a>
<ul>
<li class="chapter" data-level="4.1" data-path="monitoring-funding-to-statistics-with-reduced-reporting-lag.html"><a href="monitoring-funding-to-statistics-with-reduced-reporting-lag.html#what-is-the-reporting-lag"><i class="fa fa-check"></i><b>4.1</b> What is the reporting lag?</a></li>
<li class="chapter" data-level="4.2" data-path="monitoring-funding-to-statistics-with-reduced-reporting-lag.html"><a href="monitoring-funding-to-statistics-with-reduced-reporting-lag.html#estimating-using-CRS"><i class="fa fa-check"></i><b>4.2</b> Estimating up‐to‐date support to statistics using CRS</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="monitoring-funding-to-statistics-with-reduced-reporting-lag.html"><a href="monitoring-funding-to-statistics-with-reduced-reporting-lag.html#nowcasting-using-commitments-to-predict-current-disbursements"><i class="fa fa-check"></i><b>4.2.1</b> Nowcasting: using commitments to predict current disbursements</a></li>
<li class="chapter" data-level="4.2.2" data-path="monitoring-funding-to-statistics-with-reduced-reporting-lag.html"><a href="monitoring-funding-to-statistics-with-reduced-reporting-lag.html#forecasting-anticipating-future-funding"><i class="fa fa-check"></i><b>4.2.2</b> Forecasting: anticipating future funding</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="monitoring-funding-to-statistics-with-reduced-reporting-lag.html"><a href="monitoring-funding-to-statistics-with-reduced-reporting-lag.html#expanding-the-press-database"><i class="fa fa-check"></i><b>4.3</b> Expanding the PRESS database</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="monitoring-funding-to-statistics-with-reduced-reporting-lag.html"><a href="monitoring-funding-to-statistics-with-reduced-reporting-lag.html#exploring-alternative-data-sources-for-aid-flows-on-statistics"><i class="fa fa-check"></i><b>4.3.1</b> Exploring alternative data sources for aid flows on statistics</a></li>
<li class="chapter" data-level="4.3.2" data-path="monitoring-funding-to-statistics-with-reduced-reporting-lag.html"><a href="monitoring-funding-to-statistics-with-reduced-reporting-lag.html#addressing-gaps-in-the-alternative-data-sources"><i class="fa fa-check"></i><b>4.3.2</b> Addressing gaps in the alternative data sources</a></li>
<li class="chapter" data-level="4.3.3" data-path="monitoring-funding-to-statistics-with-reduced-reporting-lag.html"><a href="monitoring-funding-to-statistics-with-reduced-reporting-lag.html#linking-the-alternative-sources-the-new-harmonised-database"><i class="fa fa-check"></i><b>4.3.3</b> Linking the alternative sources: the new harmonised database</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="monitoring-funding-to-statistics-with-reduced-reporting-lag.html"><a href="monitoring-funding-to-statistics-with-reduced-reporting-lag.html#bringing-them-together-nowcasting-and-forecasting-with-the-new-harmonised-database"><i class="fa fa-check"></i><b>4.4</b> Bringing them together – nowcasting and forecasting with the new harmonised database</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i><b>5</b> Conclusion</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https\://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Methodology for measuring and estimating funding to data and statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="machine-learning" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">3</span> Identifying data and statistical projects using machine learning<a href="machine-learning.html#machine-learning" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>The developed method to identify data and statistical projects is based on a two-step procedure that analyzes project titles in the first step by detecting pertinent keyword (<strong>A</strong>) and evaluates project’s detailed descriptions using a machine learning approach (<strong>B</strong>).</p>
<div id="reading-the-crs-data" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> Reading the CRS data<a href="machine-learning.html#reading-the-crs-data" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>After downloading all .txt files for the years 2006 - 2020 from the official OECD <a href="https://stats.oecd.org/DownloadFiles.aspx?DatasetCode=CRS1">data base</a>, the fully merged data set is stored.</p>
</div>
<div id="preparing-the-data" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Preparing the data<a href="machine-learning.html#preparing-the-data" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Here, the process of preparing the data is outlined (see Fig. <a href="machine-learning.html#fig:data-preparation-CRS">3.1</a> for a comprehensive overview).</p>
<ol style="list-style-type: decimal">
<li><p><strong>Reducing the full CRS data set</strong></p>
<p>A known characteristic of Canadian reporting in the CRS data base is that both project titles and long descriptions<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> are reported in both official languages in the format “Englisch/French”. To avoid misclassification and misidentification due to the presence of both languages, the French part was dropped. Additionally, the full data set was reduced to 16 necessary variables to avoid heavy computational load of the full 96-variable data set.</p></li>
<li><p><strong>Adding text identifiers</strong></p>
<ol style="list-style-type: lower-roman">
<li><p><em>Text cleaning</em>: First of all, the titles and descriptions were lowercased and cleaned by removing all numbers and punctuation signs in an effort to prepare the text for the creation of unique text identifiers. This is done to avoid unnecessary inclusion of projects that differ only slightly (e.g. by a number or comma).</p></li>
<li><p><em>Id creation</em>: Each project title and description is given a specific id in order to be able to analyze only distinct titles and descriptions later on. These were created using a well-known hashing algorithm called “xxHash” that is reasonably fast and exhibits very good collision properties (see <a href="https://github.com/Cyan4973/xxHash" class="uri">https://github.com/Cyan4973/xxHash</a>).</p></li>
<li><p><em>descr2mine</em>: Due to lazy reporting, frequently the descriptions differ only marginally from the project titles. This would pose a problem to the previously outlined twofold procedure since descriptions that are identical to the project titles would be analyzed twice. Therefore, only distinct descriptions are used which are identified using the Damerau-Levenshtein-Distance that counts how many alterations it would take to align both texts. The threshold for the maximal distance was set to 10 since this includes spelling mistakes, as well as one-word deviations (e.g. “Output: …”).</p></li>
<li><p><em>Crating identifiers</em>: The CRS data set contains information about purpose of the funding flow in form of the purpose code, as well as other valuable information in other markers such as the gender marker (add link to resource) or the certain channel codes (41146 for UN Women). Table 1 lists all added identifiers.</p></li>
</ol></li>
</ol>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:data-preparation-CRS"></span>
<img src="images/data_preparation_CRS.png" alt="Diagram of the data preparation process." width="788" />
<p class="caption">
Figure 3.1: Diagram of the data preparation process.
</p>
</div>
</div>
<div id="a-title-pattern-matching" class="section level2 hasAnchor" number="3.3">
<h2><span class="header-section-number">3.3</span> <strong>A</strong>: Title pattern matching<a href="machine-learning.html#a-title-pattern-matching" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In the following, the process of matching pertinent keywords in project titles is outlined (see Fig. <a href="machine-learning.html#fig:title-pattern-matching">3.2</a> for a comprehensive overview).</p>
<ol style="list-style-type: decimal">
<li><p><strong>Preparing the data</strong></p>
<p>In the first step, the language of both title and description is detected using <a href="https://github.com/CLD2Owners/cld2">Google’s Compact Language detector 2</a> (CLD2). It can detect 83 different languages and exceeds similar language detection engines by as much as 10x in speed. Analyzing the language distribution is crucial to a refined classification since text in every language has to be treated differently, using different keywords for the subsequent title pattern matching and fitting a different machine learning model later on. Therefore, the procedure was applied to projects in English, French, Spanish and German since these make up the majority of detected languages. This was implemented by selecting only projects with combinations of (title_language, long_language) in (en, fr, es, de, NA) x (en, fr, es, de, NA) while excluding the (NA, NA) combination. This combination was excluded since CLD2 in a vast majority of cases detects NA if the text is very short or nonsensical.</p>
<p>To give an overview how many projects are analyzed using this method, this approach encompasses 3.145.387 (90.6%) projects while 23.4020 (6.7%) were excluded for being (NA, NA) projects. That leaves 90241 (2.6%) projects that were excluded because they were either wrongly detected or belonging to some minor reporting languages (e.g. Norwegian, Portuguese or Polish with a significant fraction within the 2.6% of excluded projects).</p>
<p>In the second step, duplicated project titles were dropped to analyze these titles only once during the title pattern matching procedure which again reduced computation time.</p></li>
<li><p><strong>Title pattern matching</strong></p>
<ol style="list-style-type: lower-roman">
<li><p><em>Clean and lemmatize keyword lists</em>: For the treatment of the minority languages (French, Spanish and German), the English keyword list for statistics was translated by experts working in the field of official statistics. It contains many aspects of official development assistance in statistics and can be found in Appendix 1. The keywords therein are chosen in a way that it is almost certain that a project is at least partly related to statistics if its title contains one of the keywords. The same was done for the English list of acronyms which can differ in other foreign languages. Together with the list for mining projects, the keyword lists were cleaned and lemmatized to guarantee that they will be matched to cleaned and lemmatized words occurring in project titles.</p></li>
<li><p><em>Clean and lemmatize titles</em>: Cleaning of project titles was achieved by removing numbers, punctuation and so called “stopwords” (e.g. “and”, “the”, “for”) since they don’t contain information towards the classification. Subsequently, words were lemmatized meaning to reduce different forms of a word to its lemma (e.g. “women”, “woman’s”, “woman” -&gt; “woman”). This is very important to guarantee that all various versions are found during the title pattern search. For minority languages however, stemming is used instead of lemmatization since no good lemmatization implementation was available.</p></li>
<li><p><em>Keyword detection</em>: For every language, the project title was analyzed whether it contains one of the statistical keywords or acronyms.</p></li>
<li><p><em>Merging classes for final filter</em>: The reason to detect also mining projects was to exclude those projects from the statistics filter since expressions like “small arms survey”, “survey of landmine situation” make frequent appearances in project titles but are not related to statistics. Hence, only projects for which a statistical keyword was detected but no mining keyword are marked as a statistical project in the pattern matching step.</p></li>
</ol></li>
</ol>
<p>Lastly, the statistics filter is added back to the reduced data set according to the title id. This ensures that all projects with the same title in the reduced data set are marked as statistical by the title pattern matching.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:title-pattern-matching"></span>
<img src="images/title_pattern_matching.png" alt="Schematic diagram of the title pattern matching." width="881" />
<p class="caption">
Figure 3.2: Schematic diagram of the title pattern matching.
</p>
</div>
</div>
<div id="b-text-mining-of-long-descriptions" class="section level2 hasAnchor" number="3.4">
<h2><span class="header-section-number">3.4</span> <strong>B</strong>: Text mining of long descriptions<a href="machine-learning.html#b-text-mining-of-long-descriptions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Lastly, the process of applying a machine learning approach to classify the projects’ long descriptions will be explained in detail (see Fig. <a href="machine-learning.html#fig:text-mining">3.3</a> for a comprehensive overview).</p>
<ol style="list-style-type: decimal">
<li><p><strong>Preparing the data</strong></p>
<ol style="list-style-type: lower-roman">
<li><p><em>Language filtering</em>: For the preparation of the data, the reduced data set with the additional statistics filter from the pattern matching is filtered according to the description language to ensure that the text mining is applied only to text in one language. Note that there are projects with differing title and description language (frequently English title, minority language description) which is however no problem, since a project’s description can be assumed to be statistical even when its title is in another language.</p></li>
<li><p><em>Drop duplicated text ids</em>: As for the title ids, duplicated text ids are dropped to reduce the computational load during the text mining.</p></li>
<li><p><em>Manual filter correction</em>: For 200 English projects, the description of projects, which were detected as statistical projects by the title pattern matching, were verified manually by experts. It can be the case that a projects title refers to statistics (e.g. “census aid”) while its description contains no relevant information towards a classification (“Material and equipment for on the ground operations”). This additional step makes sure that the learning set contains less errors and hence increases the accuracy.</p></li>
</ol></li>
<li><p><strong>Text mining of long description</strong></p>
<ol style="list-style-type: lower-roman">
<li><p><em>Construct learning and prediction set</em>: For this machine learning approach, it is necessary to construct a balanced learning set which contains 50% negatively marked (NM) and 50% positively marked (PM) projects. The projects detected in Step <strong>A</strong> are used as the PM projects since it is reasonable to assume that if the title contains statistical keywords, also its description refers to statistics. The NM projects are chosen randomly because it can be assumed that only a small fraction of projects refer to statistics and therefore the probability to introduce error into the learning set is very small. The prediction data set contains simply the rest of the NM projects in the text mining data set.</p></li>
<li><p><em>Clean and lemmatize descr2mine</em>: As previously discussed, only distinct long descriptions (distinct from title) are used to avoid analyzing the same text twice. These are then cleaned and lemmatized to reduce the text to the relevant information.</p></li>
<li><p><em>Create DTM matrices</em>: After splitting the learning set into the training set and testing set in a ration of 80/20, the document term matrix (DTM) is created for the training set. It has all the words that are present in all descriptions of the training data set (terms) as columns and collects their weighted frequency for each project in the respective row. For creating the DTMs of the test data and prediction data, terms occurring in the training data DTM are used which means that the all DTMs share the same columns. This is important for the prediction step later on since the model is only trained on these terms and assigns a relative weight to each of them. Therefore, it can only predict on terms that is already “seen”.</p></li>
<li><p><em>Training the XGBoost model</em>: The model is obtained from the regularizing gradient boosting framework <a href="https://xgboost.readthedocs.io/en/stable/index.html">XGBoost</a> by fitting the training data. Due to the broad literature on this machine learning approach, a detailed discussion shall be refrained from here. It can be said however that by passing along the training data DTM alongside the correct classification labels, the XGBoost model identifies the most important words appearing in the TM projects and assigns a high importance to them (see Fig. <a href="machine-learning.html#fig:importance-matrix">3.4</a> below).</p></li>
<li><p><em>Testing and prediction</em>: The model is then assessed using the test data. Since the model returns a score p_stat in the range from 0 to 1 whether a project’s description refers to statistics, different thresholds are tested to see how the model performs (more in Appendix 2). Finally, all projects in the prediction set are predicted using the fitted model. If a project receives a score of <span class="math inline">\(p_{stat} ≥ 0.9\)</span>, it is marked as statistical by the text mining (justification of threshold).</p></li>
<li><p><em>Iteration of step 1.-5. for learning set robustness</em>: In step 1, the 50% NM projects were chosen at random since the probability that statistical project is in this set is very small. However, it could still be the case that the statistical projects are included by chance. This can be almost avoided by repeating steps 1. – 5. with a training set that is constructed using only projects that are predicted not to be statistical with <span class="math inline">\(p_{stat} ≤ 0.3\)</span>. This threshold is chosen because it makes sure that the training set is only constructed from true NM projects while not being too restrictive and potentially introducing a bias into the training set (e.g. if all projects with <span class="math inline">\(p_{stat} ≤ 0.05\)</span> stem from the agriculture sector). On average, this iterative procedure increases the accuracy by 5% - 10% depending on the size of the prediction set.</p></li>
</ol></li>
</ol>
<p>Finally, the text mining filter is added back to the reduced data set according to the text id. This ensures that all projects with the same description in the reduced data set are marked as statistical by the text mining methodology.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:text-mining"></span>
<img src="images/text_mining.png" alt="Schematic diagram of the text mining." width="906" />
<p class="caption">
Figure 3.3: Schematic diagram of the text mining.
</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:importance-matrix"></span>
<img src="images/importance_matrix.png" alt="Relative importance assigned to terms appearing in long descriptions." width="426" />
<p class="caption">
Figure 3.4: Relative importance assigned to terms appearing in long descriptions.
</p>
</div>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="6">
<li id="fn6"><p>Originally both short and long description present in CRS data; from now one referred to as description<a href="machine-learning.html#fnref6" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="monitoring-funding-to-statistics-with-accuracy.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="monitoring-funding-to-statistics-with-reduced-reporting-lag.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/PARIS21-DATA/PRESS_methodology_note/blob/master/03-Identifying-data-and-statistical-projects-using-machine-learning.Rmd",
"text": null
},
"download": [["PRESS_methodology_note.pdf", "PDF"]],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"depth": 1,
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
